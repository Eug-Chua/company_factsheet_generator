company_name: "capitaland"  # Options: capitaland, grab, sea, sq, weride

# file Paths
data_folder: "data"
markdown_folder: "markdown_files"
outputs_folder: "outputs"
logs_folder: "logs"
question_set_path: "question_set.md"

pdf_files:
  capitaland: "Capitaland 2024.pdf"
  grab: "Grab 2024.pdf"
  sea: "SEA 2024.pdf"
  sq: "SQ 2024.pdf"
  weride: "WeRide 2024.pdf"
  tsla: "Tesla 2024.pdf"

embedding_model: "all-MiniLM-L6-v2"

# LLM Configuration
# Supported providers: "openai", "anthropic", "ollama"
llm_provider: "openai"

# OpenAI Configuration
openai_model: "gpt-4o-mini"

# Anthropic Configuration
anthropic_model: "claude-sonnet-4-5-20250929" 

# Ollama Configuration
ollama_model: "qwen3:14b"
ollama_url: "http://localhost:11434"

docling:
  export_format: "markdown"

chunking:
  min_chunk_size: 200
  max_chunk_size: 2000

semantic_chunking:
  similarity_threshold: 0.6
  max_merged_size: 4000

# Multi-HyDE Configuration
multi_hyde:
  enabled: true               # enable Multi-HyDE for qualitative questions
  num_variants: 5             # same as the paper
  k_per_hypothetical: 10      # same as the paper
  cross_encoder_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"